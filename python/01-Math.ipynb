{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy.signal as scs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Vectors\n",
    "\n",
    "We have two 4D vectors\n",
    "\\begin{equation*}\n",
    "    \\vec{v} = \\left(1, -2, 5, 0\\right)^\\mathrm{T}\n",
    "    \\quad\\mathrm{and}\\quad\n",
    "    \\vec{w} = \\left(2, 2, 3, -1\\right)^\\mathrm{T}\n",
    "\\end{equation*}\n",
    "\n",
    "1. Calculate the lengths $|\\vec{v}|$, $|\\vec{w}|$\n",
    "1. Calculate the sum $\\vec{v} + \\vec{w}$ and difference $\\vec{v} - \\vec{w}$\n",
    "1. Calculate the scalar product $\\vec{v}\\cdot \\vec{w}$\n",
    "1. What is angle $\\phi$ in degrees between both vectors?\n",
    "1. Find a vector $\\vec{u}\\neq \\vec{0}$ which is orthogonal to $\\vec{v}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The length of an vetor is calculated using\n",
    "\\begin{equation*}\n",
    "    |\\vec{v}| = \\sqrt{\\sum_{i=1}^n v_i^2}\n",
    "\\end{equation*}\n",
    "\n",
    "So for the first vector we get\n",
    "\\begin{equation*}\n",
    "    |\\vec{v}| = \\sqrt{1^2 + (-2)^2 + 5^2 + 0^2}\n",
    "        = \\sqrt{1 + 4 + 25 + 0} = \\sqrt{30} \\approx 5.48\n",
    "\\end{equation*}\n",
    "and for the second one\n",
    "\\begin{equation*}\n",
    "    |\\vec{v}| = \\sqrt{2^2 + 2^2 + 3^2 + (-1)^2}\n",
    "        = \\sqrt{4 + 4 + 9 + 1} = \\sqrt{18} \\approx 4.24\n",
    "\\end{equation*}\n",
    "\n",
    "See cell below for the computational solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computational solution for vector exercise 1\n",
    "v = [1, -2, 5, 0]\n",
    "w = [2, 2, 3, -1]\n",
    "\n",
    "\n",
    "## Using numpy\n",
    "norm_v = np.linalg.norm(v)\n",
    "norm_w = np.linalg.norm(w)\n",
    "print(\"# Using numpy methods:\")\n",
    "print(\"Length of v: {:.2f}\".format(norm_v))\n",
    "print(\"Length of w: {:.2f}\".format(norm_w))\n",
    "\n",
    "\n",
    "## Using standard python\n",
    "def vec_norm(v):\n",
    "    \"\"\" Calculates the norm of given vector v, input as list \"\"\"\n",
    "    return math.sqrt(sum([vi**2 for vi in v]))\n",
    "\n",
    "norm_v = vec_norm(v)\n",
    "norm_w = vec_norm(w)\n",
    "print(\"\\n# Using standard methods:\")\n",
    "print(\"Length of v: {:.2f}\".format(norm_v))\n",
    "print(\"Length of w: {:.2f}\".format(norm_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The sum is simply computed by adding each corresponding elements:\n",
    "\\begin{equation}\n",
    " \\vec{v} + \\vec{w} =\n",
    " \\left(1 + 2, -2 + 2, 5 + 3, 0 - 1\\right)^\\mathrm{T} =\n",
    " \\left(3, 0, 8, -1\\right)^\\mathrm{T}\n",
    "\\end{equation}\n",
    "The same for the difference:\n",
    "\\begin{equation}\n",
    " \\vec{v} - \\vec{w} =\n",
    " \\left(1 - 2, -2 - 2, 5 - 3, 0 + 1\\right)^\\mathrm{T} =\n",
    " \\left(-1, -4, 2, 1\\right)^\\mathrm{T}\n",
    "\\end{equation}\n",
    "\n",
    "See cell below for computational solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computational solution for vector exercise 2\n",
    "v = [1, -2, 5, 0]\n",
    "w = [2, 2, 3, -1]\n",
    "\n",
    "\n",
    "## Using numpy\n",
    "u1 = np.array(v) + np.array(w)\n",
    "u2 = np.array(v) - np.array(w)\n",
    "print(\"# Using numpy methods:\")\n",
    "print(\"v + w = ({})^T\".format(\n",
    "    \", \".join([\"{:.2f}\".format(ui) for ui in u1])))\n",
    "print(\"v - w = ({})^T\".format(\n",
    "    \", \".join([\"{:.2f}\".format(ui) for ui in u2])))\n",
    "\n",
    "\n",
    "# Using standard python\n",
    "u1 = [vi + wi for vi, wi in zip(v, w)]\n",
    "u2 = [vi - wi for vi, wi in zip(v, w)]\n",
    "print(\"\\n# Using standard methods:\")\n",
    "print(\"v + w = ({})^T\".format(\n",
    "    \", \".join([\"{:.2f}\".format(ui) for ui in u1])))\n",
    "print(\"v - w = ({})^T\".format(\n",
    "    \", \".join([\"{:.2f}\".format(ui) for ui in u2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the scalar product we add the products of each corresponding components\n",
    "\\begin{equation}\n",
    " \\vec{v} \\cdot \\vec{w} = \\sum_{i=1}^n v_i w_i\n",
    "\\end{equation}\n",
    "and get\n",
    "\\begin{equation}\n",
    " \\vec{v} \\cdot \\vec{w} =\n",
    " 1 \\cdot 2 + -2 \\cdot 2 + 5 \\cdot 3 + 0 \\cdot (- 1) =\n",
    " 2 - 4 + 15 +0 = 13\n",
    "\\end{equation}\n",
    "for the example vectors.\n",
    "\n",
    "See cell below for the computational solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computational solution for vector exercise 3\n",
    "v = [1, -2, 5, 0]\n",
    "w = [2, 2, 3, -1]\n",
    "\n",
    "\n",
    "## Using numpy\n",
    "a = np.dot(v, w)\n",
    "print(\"# Using numpy methods:\")\n",
    "print(\"v * w = {:.2f}\".format(a))\n",
    "\n",
    "\n",
    "# Using standard python\n",
    "a = sum([vi * wi for vi, wi in zip(v, w)])\n",
    "print(\"\\n# Using standard methods:\")\n",
    "print(\"v * w = {:.2f}\".format(a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the angle $\\phi$ we use the alternative formula\n",
    "\\begin{equation}\n",
    "    \\cos(\\phi) =\n",
    "    \\frac{\\vec{v} \\cdot \\vec{w}}{|\\vec{v}|\\,|\\vec{w}|}\n",
    "\\end{equation}\n",
    "\n",
    "We already computed all the ingredients (lengths and the scalar product) in the other exercises so we can reuse them here.\n",
    "Using the inverse cosine we get\n",
    "\\begin{align}\n",
    "     \\cos(\\phi)\n",
    "     &= \\arccos\\left(\n",
    "         \\frac{\\vec{v} \\cdot \\vec{w}}{|\\vec{v}|\\,|\\vec{w}|}\n",
    "     \\right) \\\\\n",
    "     &= \\arccos\\left(\\frac{13}{5.48 * 4.24}\\right)\n",
    "     \\approx \\arccos(0,56) = 0,98 = 55,98째\n",
    "\\end{align}\n",
    "\n",
    "See cell below for the computational solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Computational solution for vector exercise 4\n",
    "v = [1, -2, 5, 0]\n",
    "w = [2, 2, 3, -1]\n",
    "\n",
    "cos_phi = np.dot(v, w) / (np.linalg.norm(v) * np.linalg.norm(w))\n",
    "phi = np.arccos(cos_phi)\n",
    "phi_deg = np.rad2deg(phi)\n",
    "print(\"The angle is {:.2f}째\".format(phi_deg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To find a orthogonal vector we first note that two vectors are orthogonal when their scalar product vanishes.\n",
    "Then $\\cos(\\phi) = 0 \\rightarrow \\phi = 90째$.\n",
    "This problem does not have a unique solution.\n",
    "To get on possible solution, we can fix 3 of the 4 unknown components of $\\vec{u}$ and then solve a single equation to find the 4th one which then fullfills the requirement:\n",
    "Here we simply use the 1st, 2nd and 4th component of $\\vec{w}$ for $\\vec{u}$ which results in the orthogonal vector\n",
    "\\begin{align}\n",
    "    \\vec{v}\\cdot\\vec{u} \\overset{!}{=} 0 &=\n",
    "    1 \\cdot 2 + -2 \\cdot 2 + 5 \\cdot u_3 + 0 \\cdot -1 \\\\\n",
    "    u_3 &= \\frac{2}{-5} + \\frac{-4}{-5}\n",
    "    = \\frac{2}{5}\n",
    "\\end{align}\n",
    "\n",
    "Alternatively we could also have noted that the 4th component of $\\vec{v}$ is $0$, so any vector of the form $(0, 0, 0, u_4)^\\mathrm{T}$ is automatically orthogonal to $\\vec{v}$.\n",
    "\n",
    "See cell below for the computational solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Computational solution for vector exercise 5\n",
    "# Here we just prove we found an orthogonal vector,\n",
    "# because an actual computation is more complicated\n",
    "v = [1, -2, 5, 0]\n",
    "u = [2, 2, 2. / 5., -1]\n",
    "\n",
    "cos_phi = np.dot(v, u) / (np.linalg.norm(v) * np.linalg.norm(u))\n",
    "phi = np.arccos(cos_phi)\n",
    "phi_deg = np.rad2deg(phi)\n",
    "print(\"The angle is {:.2f}째\".format(phi_deg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Matrices\n",
    "\n",
    "1. We have 2 matrices $\\underline{A}, \\underline{B}$\n",
    "  and a vector $\\vec{v}$\n",
    "  \\begin{equation*}\n",
    "    \\underline{A} =\n",
    "      \\begin{pmatrix} 1 & 2 & 3 \\\\ 3 & 2 & 1 \\end{pmatrix}\n",
    "    \\,\\mathrm{, }\\quad\n",
    "    \\underline{B} =\n",
    "      \\begin{pmatrix} 0 & 2 \\\\ 1 & -1 \\\\ 0 & 1 \\end{pmatrix}\n",
    "    \\,\\mathrm{, }\\quad\n",
    "    \\vec{v} = \\begin{pmatrix} 4 \\\\ 5 \\\\ 6 \\end{pmatrix}\n",
    "  \\end{equation*}\n",
    "  Calculate $\\underline{A}\\,\\underline{B}$,\n",
    "  $\\underline{B}\\,\\underline{A}$,\n",
    "  $\\underline{A}\\,\\vec{v}$ and $\\vec{v}^\\mathrm{T}\\,\\underline{B}$.\n",
    "1. Calculate the inverses (if existing) of\n",
    "  \\begin{equation*}\n",
    "    \\underline{A} =\n",
    "      \\begin{pmatrix} 1 & 2 \\\\ 4 & 2 \\end{pmatrix}\n",
    "    \\quad\\mathrm{, }\\quad\n",
    "    \\underline{B} =\n",
    "      \\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}\n",
    "  \\end{equation*}\n",
    "1. We have a matrix $\\underline{M} = \\underline{1}$\n",
    "  and a vector $\\vec{v}^\\mathrm{T} = \\left(v_1, v_2, v_3\\right)$.\n",
    "  Calculate\n",
    "  \\begin{equation*}\n",
    "    \\vec{v}^\\mathrm{T}\\, \\underline{M}\\, \\vec{v}\n",
    "  \\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We only calculate $\\underline{A}\\,\\underline{B}$ explicitely here, the rest is done in code.\n",
    "\\begin{align}\n",
    "    \\underline{A}\\,\\underline{B} &=\n",
    "    \\begin{pmatrix} \n",
    "        1 & 2 & 3 \\\\ 3 & 2 & 1 \\end{pmatrix}_{2,3}\n",
    "    \\begin{pmatrix}\n",
    "        0 & 2 \\\\ 1 & -1 \\\\ 0 & 1 \\end{pmatrix}_{3, 2} \\\\\n",
    "    &=\n",
    "    \\begin{pmatrix}\n",
    "        1 \\cdot 0 + 2 \\cdot 1 + 3 \\cdot 0 &\n",
    "        1 \\cdot 2 + 2 \\cdot -1 + 3 \\cdot 1 \\\\\n",
    "        3 \\cdot 0 + 2 \\cdot 1 + 1 \\cdot 0 &\n",
    "        3 \\cdot 2 + 2 \\cdot -1 + 1 \\cdot 1\n",
    "    \\end{pmatrix}_{2,2} = \n",
    "    \\begin{pmatrix}\n",
    "        2 & 3 \\\\ 2 & 5\n",
    "    \\end{pmatrix}_{2,2}\n",
    "\\end{align}\n",
    "\n",
    "See cell below for the computational solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Computational solution for matrix exercise 1\n",
    "A = [[1, 2, 3], [3, 2, 1]]  # row-wise definition as in C\n",
    "B = [[0, 2], [1, -1], [0, 1]]\n",
    "v = np.array([[4], [5], [6]])  # Using an explicit column vector\n",
    "\n",
    "AB = np.matmul(A, B)\n",
    "BA = np.matmul(B, A)\n",
    "Av = np.matmul(A, v)\n",
    "vB = np.matmul(v.T, B)\n",
    "dimAB = AB.shape\n",
    "dimBA = BA.shape\n",
    "dimAv = Av.shape\n",
    "dimvB = vB.shape\n",
    "\n",
    "print(\"AB =\\n{}\".format(AB))\n",
    "print(\"  Dimensions: {}\".format(dimAB))\n",
    "print(\"\\nBA =\\n{}\".format(BA))\n",
    "print(\"  Dimensions: {}\".format(dimBA))\n",
    "print(\"\\nAv =\\n{}\".format(Av))\n",
    "print(\"  Dimensions: {}\".format(dimAv))\n",
    "print(\"\\nvB = {}\".format(vB))\n",
    "print(\"  Dimensions: {}\".format(dimvB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For these $(2,2)$ matrices we can use the explicit formula for the inverse\n",
    "\\begin{equation}\n",
    "  \\underline{A}^{-1} =\n",
    "  \\frac{1}{1 \\cdot 2 - 4 \\cdot 2}\n",
    "  \\begin{pmatrix}2 & -2 \\\\ -4 & 1\\end{pmatrix} =\n",
    "  \\begin{pmatrix}\n",
    "      -\\frac{1}{3} & \\frac{1}{3} \\\\\n",
    "      \\frac{2}{3} & -\\frac{1}{6}\n",
    "  \\end{pmatrix}\n",
    "\\end{equation}\n",
    "\n",
    "The inverse of $\\underline{B}$ does not exist, because both rows are multiples of each other.\n",
    "This mean it has not full rank or one of its eigenvalues is $0$ or the denominator of the factor for the inverse computation (\"determinant\") is zero\n",
    "\\begin{equation}\n",
    "  \\frac{1}{1 \\cdot 4 - 2 \\cdot 2} = \\frac{1}{0}\n",
    "\\end{equation}\n",
    "\n",
    "See cell below for the computational solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Computational solution for matrix exercise 2\n",
    "A = [[1, 2], [4, 2]]\n",
    "B = [[1, 2], [2, 4]]\n",
    "\n",
    "Ainv = np.linalg.inv(A)\n",
    "test1 = np.matmul(Ainv, A)\n",
    "test2 = np.matmul(A, Ainv)\n",
    "print(\"Ainv =\\n{}\".format(Ainv))\n",
    "print(\"  Dimensions: {}\".format(Ainv.shape))\n",
    "print(\"Test if Ainv * A is identity:\")\n",
    "print(\"  Ainv * A =\\n{}\".format(test1))\n",
    "print(\"  A * Ainv =\\n{}\".format(test2))\n",
    "\n",
    "# This will fail\n",
    "try:\n",
    "    Binv = np.linalg.inv(B)\n",
    "except np.linalg.LinAlgError as err:\n",
    "    print(\"\\nCalculation of inverse of B failed, reason: \", err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This form is equivalent to computing the scalar product of $\\vec{v}$ with itself but using the matrix multiplication formalism:\n",
    "\\begin{equation}\n",
    "    \\vec{v}^\\mathrm{T}\\,\\underline{1}\\,\\vec{v} =\n",
    "    \\left(v_1, v_2, v_3\\right)\n",
    "    \\begin{pmatrix}\n",
    "     1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1\n",
    "    \\end{pmatrix}\n",
    "    \\begin{pmatrix}v_1 \\\\ v_2 \\\\ v_3\\end{pmatrix} =\n",
    "    v_1^2 + v_2^2 + v_3^2 =\n",
    "    \\vec{v} \\cdot \\vec{v}\n",
    "\\end{equation}\n",
    "The result would be identical without the identity matrix in the center.\n",
    "\n",
    "Note: In a multidimensional gaussian the same form is used, but with the inverse covariance matrix in the middle\n",
    "\\begin{equation}\n",
    "    \\mathcal{N}(\\vec{\\mu}, \\underline{\\Sigma}) \\propto\n",
    "    \\exp\\left(\n",
    "        -\\frac{1}{2}\n",
    "        \\left(\\vec{x}-\\vec{\\mu}\\right)^\\mathrm{T}\n",
    "        \\Sigma^{-1}\n",
    "        \\left(\\vec{x}-\\vec{\\mu}\\right)\n",
    "    \\right)\n",
    "\\end{equation}\n",
    "so that in the end the exponential receives a single number as the argument.\n",
    "\n",
    "See cell below for the computational solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Computational solution for matrix exercise 3\n",
    "v = np.array([[1], [2], [3]])  # As an example\n",
    "ID = np.eye(len(v))\n",
    "res = np.matmul(np.matmul(v.T, ID), v)\n",
    "\n",
    "v = [1, 2, 3]  # Flat vector only version\n",
    "comp = np.dot(v, v)\n",
    "\n",
    "print(\"Matrix: vT * 1 * v = {}\".format(res))  # Gives a (1, 1) matrix\n",
    "print(\"Vector: v * v = {}\".format(comp))  # Gives a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution\n",
    "\n",
    "For the following exercises, pad the signal function with zeroes where appropriate.\n",
    "Additionally you can also try cyclic, mirrored or \"expanded\" edges or only calculate the convolution where the signal is valid.\n",
    "\n",
    "1. Consider a discrete signal $f[i] = 3\\delta[i]$ (value of $3$ at position $i=0$) and a response $g[i] = \\left\\{g[i=0] = 2, g[i=1] = 1\\right\\}$.\n",
    "Compute the convolution $f*g$ for all non-zero components.\n",
    "1. Now we have a more complicated signal $f[i] = \\left\\{f[i=0] = 3, f[i=1] = 4, f[i=2] = 5\\right\\}$.\n",
    "Compute $f*g$ with the same kernel $g$ as above.\n",
    "Tip: \\emph{For grasping the concept of why the kernel is flipped, try to imagine how each signal contribution triggered the response. The response needs some time to arrive at the current index which in the end gives you the flipped response in the formula.}\n",
    "1. Now we try a 2D convolution.\n",
    "    Convolve the following $8x8$ \"grayscale image\"\n",
    "    \\begin{equation*}\n",
    "        \\mathrm{Img}_1 = \\begin{pmatrix}\n",
    "            1.  & 0.5 & 0.5 & 0.5 & 0.5 & 0.5 & 0.5 & 1.  \\\\\n",
    "            1.  & 1.  & 0.5 & 0.5 & 0.5 & 0.5 & 1.  & 1.  \\\\\n",
    "            1.  & 1.  & 1.  & 1.  & 1.  & 1.  & 1.  & 1.  \\\\\n",
    "            1.  & 1.  & 1.  & 1.  & 1.  & 1.  & 1.  & 1.  \\\\\n",
    "            1.  & 0.  & 0.  & 1.  & 1.  & 0.  & 0.  & 1.  \\\\\n",
    "            1.  & 1.  & 1.  & 1.  & 1.  & 1.  & 1.  & 1.  \\\\\n",
    "            1.  & 1.  & 0.3 & 0.4 & 0.4 & 0.3 & 1.  & 1.  \\\\\n",
    "            0.5 & 1.  & 0.3 & 0.3 & 0.3 & 0.3 & 1.  & 0.5\n",
    "        \\end{pmatrix}\n",
    "    \\end{equation*}\n",
    "    with a $3x3$ top to bottom Sobel kernel (gradient kernel for edge finding):\n",
    "    \\begin{equation*}\n",
    "        \\begin{pmatrix}\n",
    "            -1 & -2 & -1 \\\\\n",
    "            0 & 0 & 0 \\\\\n",
    "            1 & 2 & 1\n",
    "        \\end{pmatrix}\n",
    "    \\end{equation*}\n",
    "    Interpret the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def convolve1D(signal, kernel, mode=\"same\"):\n",
    "    \"\"\"\n",
    "    Signal is padded with zeroes. mode in ['full', 'same'], see scipy.\n",
    "    \"\"\"\n",
    "    if mode not in [\"full\", \"same\"]:\n",
    "        raise ValueError(\"'mode' must be one of 'full', 'same'.\")\n",
    "    \n",
    "    signal = np.atleast_1d(signal)\n",
    "    kernel = np.atleast_1d(kernel)\n",
    "    \n",
    "    # Fits either centralized (odd) or even kernel\n",
    "    sig_w, kern_w = len(signal), len(kernel)\n",
    "    pad_w = kern_w // 2\n",
    "    pad = np.concatenate((pad_w * [0], signal, pad_w * [0]))\n",
    "\n",
    "    if mode == \"same\":\n",
    "        # Same size as input, do not extend into the padded area in the end,\n",
    "        # even if we could due to the kernel size\n",
    "        out = np.zeros_like(signal)\n",
    "    else:\n",
    "        # At the signal end, we can convolve until we run out of kernel values\n",
    "        out = np.zeros(shape=(sig_w + pad_w))\n",
    "        \n",
    "    # Iterate image pixels\n",
    "    for i in range(len(out)):\n",
    "            # Iterate kernel\n",
    "            for ki in range(kern_w):\n",
    "                    # Pad index: Respect padded image (+pad_w), kernel is NOT\n",
    "                    # centered in 1D (in images it is, so we need 2*pad_w there)\n",
    "                    out[i] += pad[i + pad_w - ki] * kernel[ki]\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def convolve2D(img, kernel):\n",
    "    \"\"\"\n",
    "    Simple 2D convolution, uses zero padding. Output is same size as input.\n",
    "    \"\"\"\n",
    "    img = np.atleast_2d(img)\n",
    "    img_h, img_w = img.shape\n",
    "    kernel = np.atleast_2d(kernel)\n",
    "    kern_h, kern_w = kernel.shape\n",
    "    # Pad img with zeros (fits odd and even kernels in each dimension)\n",
    "    pad_w, pad_h = kern_w // 2, kern_h // 2\n",
    "    pad = np.zeros(shape=(img_h + pad_h * 2, img_w + pad_w * 2))\n",
    "    pad[pad_h:img_h + pad_h, pad_w:img_w + pad_w] = img\n",
    "\n",
    "    out = np.zeros_like(img)\n",
    "    # Iterate image pixels\n",
    "    for i in range(img_h):  # First dimension (rows)\n",
    "        for j in range(img_w):  # Second dimension (cols)\n",
    "            # Iterate kernel\n",
    "            for ki in range(kern_h):  # rows\n",
    "                for kj in range(kern_w):  # cols\n",
    "                    # Pad index: Respect padded image (+pad_*) and centered\n",
    "                    # kernel (another +pad_*)\n",
    "                    out[i, j] += (pad[i + 2 * pad_h - ki, j + 2 * pad_w - kj] *\n",
    "                                  kernel[ki, kj])\n",
    "                    # print(\"i = {}, j = {}, ki = {}, kj = {}\".format(i, j, ki, kj))\n",
    "                    # print(\"pad[{}, {}] = {}\".format(i + 2 * pad_h - ki,\n",
    "                    #     j + 2 * pad_w - kj, pad[i + 2 * pad_h - ki, j + 2 * pad_w - kj]))\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def make_conv_plot(signal, kernel, conv):\n",
    "    signal = np.atleast_1d(signal)\n",
    "    kernel = np.atleast_1d(kernel)\n",
    "    conv = np.atleast_1d(conv)\n",
    "    \n",
    "    fig, (axt, axc, axb) = plt.subplots(\n",
    "        3, 1, figsize=(5, 5), sharex=True, sharey=True)\n",
    "    # Top: Signal\n",
    "    axt.plot(np.arange(len(signal)), signal, marker=\"o\", color=\"C7\", ls=\"\")\n",
    "    axt.vlines(np.arange(len(signal)), 0, signal, color=\"C7\")\n",
    "    axt.set_title(\"Signal\")\n",
    "    axt.grid()\n",
    "    # Middle: Kernel\n",
    "    axc.plot(np.arange(len(kernel)), kernel, marker=\"o\", color=\"C7\", ls=\"\")\n",
    "    axc.vlines(np.arange(len(kernel)), 0, kernel, color=\"C7\")\n",
    "    axc.set_title(\"Kernel\")\n",
    "    axc.grid()\n",
    "    # Bottom: Convolution\n",
    "    axb.plot(np.arange(len(conv)), conv, marker=\"o\", color=\"C7\", ls=\"\")\n",
    "    axb.vlines(np.arange(len(conv)), 0, conv, color=\"C7\")\n",
    "    axb.set_xlabel(\"index\")\n",
    "    axb.set_title(\"Convolution\")\n",
    "    axb.grid()\n",
    "    for axi in (axt, axc, axb):\n",
    "        axi.set_ylim(0, 1 + np.max(conv))\n",
    "        # Only int ticks (stackoverflow.com/questions/30914462)\n",
    "        axi.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        axi.yaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    \n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def make_kernel_boundary_at(row, col, kernel):\n",
    "    \"\"\"\n",
    "    Make rectangle border from given kernel, (row, col) is the center point.\n",
    "    \"\"\"\n",
    "    kernel = np.atleast_2d(kernel)\n",
    "    h, w = kernel.shape\n",
    "    \n",
    "    # Make boundaries, w, h one wider because pixels shall be enclosed (border)\n",
    "    xs = np.array([0, w, w, 0, 0])\n",
    "    ys = np.array([0, 0, h, h, 0])\n",
    "    # Shift origin to center (even kernels are centered to bottom right)(scipy)\n",
    "    col -= w // 2\n",
    "    row -= h // 2\n",
    "    \n",
    "    if w % 2 == 0:  # Even kernel horizontal\n",
    "        col += 0  # Explicit, do not delete. If += 1, then center is top left\n",
    "    if h % 2 == 0:  # Even kernel vertical\n",
    "        row += 0  # Eplicit\n",
    "        \n",
    "    return col + xs, row + ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We call the convolved output array $y[i]$ .\n",
    "The convolution formula is\n",
    "\\begin{equation*}\n",
    "    y[i] = (f*g)[i] = \\sum_{k=-\\infty}^{\\infty} f[k]g[i-k]\n",
    "\\end{equation*}\n",
    "\n",
    "Setting the formula aside for a moment, we can derive the soultion intuitively here.\n",
    "We also assume that the signal and the kernel is zero (padded) for every not explicitely defined index.\n",
    "Also the both kernel and signal arrays are assumend to start at the same \"time\" index $0$.\n",
    "\n",
    "As we have no other contributions from the signal except the single peak, the output is simply the kernel array scaled with the signal value:\n",
    "\\begin{align*}\n",
    "y[0] &= f[0] \\cdot g[0] = 6 \\\\\n",
    "y[1] &= f[0] \\cdot g[1] = 3 \\\\\n",
    "y[i] &= 0 \\mathrm{\\,for\\,} i > 1\n",
    "\\end{align*}\n",
    "\n",
    "This is exactly the same result we would get when using the explicit convolution formula:\n",
    "\\begin{align*}\n",
    "y[0] &= f[0] \\cdot g[0 - 0] + f[1] \\cdot g[0 - 1] + \\dots =\n",
    "    3 \\cdot 2 + 0 \\cdot 0 + 0 + \\dots = 6 \\\\\n",
    "y[1] &= f[0] \\cdot g[1 - 0] + f[1] \\cdot g[1 - 1] + \\dots =\n",
    "    3 \\cdot 1 + 0 \\cdot 2 + 0 + \\dots = 3 \\\\\n",
    "y[i] &= 0 \\mathrm{\\,for\\,} i > 1\n",
    "\\end{align*}\n",
    "\n",
    "See cell below for the computational solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Computational solution for convolution exercise 1\n",
    "signal = [3,]\n",
    "kernel = [2, 1]\n",
    "\n",
    "mode = \"full\"\n",
    "conv_own = convolve1D(signal, kernel, mode=mode)\n",
    "conv_scipy = scs.convolve(signal, kernel, mode=mode)\n",
    "\n",
    "print(\"Mode: {}\".format(mode))\n",
    "print(\"  Own  : \", conv_own)\n",
    "print(\"  Scipy: \", conv_scipy)\n",
    "print(\"  Both equal: {}\".format(\n",
    "    \"True\" if np.allclose(conv_scipy, conv_own) else \"False\"))\n",
    "\n",
    "make_conv_plot(signal, kernel, conv_own)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now that we know how a single input peak behaves, the convolution of a larger signal is also easy to understand: We convolve every single peak with the response and then sum each individual result.\n",
    "\n",
    "Using the explicit convolution formula:\n",
    "\\begin{align*}\n",
    "y[0] &= f[0] \\cdot g[0 - 0] +\n",
    "        f[1] \\cdot g[0 - 1] +\n",
    "        f[2] \\cdot g[0 - 2] + \\dots \\\\\n",
    "    &= 3 \\cdot 2 + 4 \\cdot 0 + 5 \\cdot 0 + \\dots = 6 \\\\\n",
    "y[1] &= f[0] \\cdot g[1 - 0] +\n",
    "        f[1] \\cdot g[1 - 1] +\n",
    "        f[2] \\cdot g[1 - 2] + \\dots \\\\\n",
    "    & = 3 \\cdot 1 + 4 \\cdot 2 + 5 \\cdot 0 + \\dots = 11 \\\\\n",
    "y[2] &= f[0] \\cdot g[2 - 0] +\n",
    "        f[1] \\cdot g[2 - 1] +\n",
    "        f[2] \\cdot g[2 - 2] + \\dots \\\\\n",
    "    &= 3 \\cdot 0 + 4 \\cdot 1 + 5 \\cdot 2 + \\dots = 14 \\\\\n",
    "y[3] &= f[0] \\cdot g[3 - 0] +\n",
    "        f[1] \\cdot g[3 - 1] +\n",
    "        f[2] \\cdot g[3 - 2] + \\dots \\\\\n",
    "    &= 3 \\cdot 0 + 4 \\cdot 0 + 5 \\cdot 1 + \\dots = 5\n",
    "\\end{align*}\n",
    "\n",
    "See cell below for the computational solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Computational solution for convolution exercise 2\n",
    "signal = [3, 4, 5]\n",
    "kernel = [2, 1]\n",
    "\n",
    "mode = \"full\"\n",
    "conv_own = convolve1D(signal, kernel, mode=mode)\n",
    "conv_scipy = scs.convolve(signal, kernel, mode=mode)\n",
    "\n",
    "print(\"Mode: {}\".format(mode))\n",
    "print(\"  Own  : \", conv_own)\n",
    "print(\"  Scipy: \", conv_scipy)\n",
    "print(\"  Both equal: {}\".format(\n",
    "    \"True\" if np.allclose(conv_scipy, conv_own) else \"False\"))\n",
    "\n",
    "make_conv_plot(signal, kernel, conv_own)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we do the same thing as in the 1D case, but we sum over both horizontal and vertical indices.\n",
    "We pick the image index $(5, 3)$ to calculate an example by hand:\n",
    "\\begin{align}\n",
    "    y[2, 3] = \n",
    "        &f[4, 2] \\cdot g[2, 2] +\n",
    "            f[4, 3] \\cdot g[2, 1] +\n",
    "            f[4, 4] \\cdot g[2, 0] + \\\\  % Upper img row\n",
    "        &f[5, 2] \\cdot g[1, 2] + \n",
    "            f[5, 3] \\cdot g[1, 1] + \n",
    "            f[5, 4] \\cdot g[1, 0] + \\\\  % Center img row\n",
    "        &f[6, 2] \\cdot g[0, 2] + \n",
    "            f[6, 3] \\cdot g[0, 1] + \n",
    "            f[6, 4] \\cdot g[0, 0] \\\\  % Lower img row = \n",
    "        & 1 \\cdot -1 +\n",
    "            0 \\cdot -2 +\n",
    "            0 \\cdot -1 + \\\\\n",
    "        & 0 \\cdot 0 + \n",
    "            0 \\cdot 0 + \n",
    "            0 \\cdot 0 + \\\\\n",
    "        & 0.7 \\cdot 1 + \n",
    "            0.6 \\cdot 2 + \n",
    "            0.6 \\cdot 1 \\\\ =\n",
    "        & -1 + 0 + (0.7 + 1.2 + 0.6) = 1.5\n",
    "\\end{align}\n",
    "\n",
    "Note 1: The kernel indices are assumed to be symmetrical in image\n",
    "convolutions (just per convention) so this differs a bit from\n",
    "1D signals where the kernel is taken to start from the leftmost coordinate at $t=0$.\n",
    "\n",
    "Note 2: The kernel is flipped horizontally and vertically, so the top image row is multiplied with the reversed bottom kernel row, etc.\n",
    "\n",
    "See cell below for the computational solution.\n",
    "The computed example pixel is highlighted in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Computational solution for convolution exercise 3\n",
    "# img = np.array(6 * [[0, 0, 1, 3, 0, 0]])\n",
    "# kernel = np.array(3 * [[0, 1, 0]])\n",
    "img = np.array([  # Batman\n",
    "    [0.0, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.0],\n",
    "    [0.0, 0.0, 0.5, 0.5, 0.5, 0.5, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.7, 0.6, 0.6, 0.7, 0.0, 0.0],\n",
    "    [0.5, 0.0, 0.7, 0.7, 0.7, 0.7, 0.0, 0.5]\n",
    "])\n",
    "kernel = np.array([  # Sobel kernel (top to bottom gradient)\n",
    "    [ 1,  2,  1],\n",
    "    [ 0,  0,  0],\n",
    "    [-1, -2, -1]\n",
    "])\n",
    "print(\"Image:\\n\", img)\n",
    "print(\"\\nKernel:\\n\", kernel)\n",
    "\n",
    "conv_scipy = scs.convolve2d(img, kernel, mode=\"same\")\n",
    "conv_own = convolve2D(img, kernel)\n",
    "\n",
    "print(\"\\nScipy:\\n\", conv_scipy)\n",
    "print(\"\\nOwn:\\n\", conv_own)\n",
    "\n",
    "# Note: Difference from non centered kernels seems to be from which direction is\n",
    "# preferred when applying the kernel. Mine is top left, scipys is bottom right?\n",
    "print(\"\\nBoth equal: {}\".format(\n",
    "    \"True\" if np.allclose(conv_scipy, conv_own) else \"False\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Example pixel and kernel borders\n",
    "cntr_x, cntr_y = 5, 3\n",
    "exmpl_xs_cntr, exmpl_ys_cntr = make_kernel_boundary_at(cntr_x, cntr_y, [[0]])  # dummy\n",
    "exmpl_xs_kern, exmpl_ys_kern = make_kernel_boundary_at(cntr_x, cntr_y, kernel)\n",
    "\n",
    "plt.matshow(img, cmap=\"Greys_r\", extent=(0, img.shape[1], img.shape[0], 0))\n",
    "plt.plot(exmpl_xs_cntr, exmpl_ys_cntr, c=\"C2\", lw=3)  # Example pixel\n",
    "plt.plot(exmpl_xs_kern, exmpl_ys_kern, c=\"C3\", lw=3)  # Kernel region\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.title(\"Image\")\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(kernel, cmap=\"Greys_r\", extent=(0, kernel.shape[1], kernel.shape[0], 0))\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.title(\"Kernel\")\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(conv_scipy, cmap=\"Greys_r\",\n",
    "            extent=(0, conv_scipy.shape[1], conv_scipy.shape[0], 0))\n",
    "plt.plot(exmpl_xs_cntr, exmpl_ys_cntr, c=\"C2\", lw=3)  # Example pixel\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.title(\"Convolution scipy\")\n",
    "plt.show()\n",
    "\n",
    "plt.matshow(conv_own, cmap=\"Greys_r\",\n",
    "            extent=(0, conv_own.shape[1], conv_own.shape[0], 0))\n",
    "plt.plot(exmpl_xs_cntr, exmpl_ys_cntr, c=\"C2\", lw=3)  # Example pixel\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "plt.title(\"Convolution own\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
