\input{header}

% Main title, author etc. in header
\subtitle{Part I -- Math and Minimizers\\\vspace*{1.5ex}
  \small \textbf{Goal:} Give a short reminder of the underlying math of machine learning algorithms
}

\begin{document}
  \input{listing_setup}
  \maketitle

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MATH
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \section{Math}

% vectors and matrices %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \subsection{Vectors and Matrices}

% <Vectors>
  \begin{frame}[fragile]{Vectors}
    \begin{itemize}
      \item Vectors have both magnitude ($|\vec{v}| \geq 0$) and direction
        \rightarrow \enquote{arrow}
      \item Vectors are represented by components indicating their length
        along the basis directions
      \item Usually we write column vectors,
        \enquote{rotate} a vector up to get the transposed version
        \begin{equation*}
          \left(v_1, v_2, \dots, v_n\right)^\transp \coloneqq
          \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix}
        \end{equation*}
      \item Vectors can be added by putting the end of one vector at the tip
        of another one. Equivalent to summing each individual components
        \begin{equation*}
          \vec{v} + \vec{w} =
            \left(v_1 + w_1, v_2 + w_2, \dots, v_n + w_n\right)^\transp
        \end{equation*}
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=6, title=\lsttitlelight{Vectors in numpy -- Examples for presented content}]
      import numpy as np
      v, w = np.array([1, 2, 3]), np.array([4, 5, 6])
      print(v + w)  # numpy adds componentwise per default -> array([5, 7, 9])
      print(v - w)  # -> array([-3, -3, -3])
      \end{lstlisting}
    \end{mdframed}
  \end{frame}

  \begin{frame}[fragile]{Vectors}
    \begin{itemize}
      \item Scalar multiplication:
        Multiply every component with the scalar $\alpha$
        \begin{equation*}
          \alpha \vec{v} =
            \alpha \left(v_1, v_2, \dots, v_n\right)^\transp =
            \left(\alpha v_1, \alpha v_2, \dots, \alpha v_n\right)^\transp
        \end{equation*}
      \item Norm (length) of a vector
        \begin{equation*}
          |\vec{v}| = \sqrt{\vec{v}\cdot \vec{v}} =
            \sqrt{v_1^2 + v_2^2 + \dots + v_n^2}
        \end{equation*}
      \item Scalar product (also \enquote{inner product}):
        Multiply each element and sum up, produces a single number $\beta$
        \begin{equation*}
          \vec{v}\cdot \vec{w} =
            v_1 w_1 + v_2 w_2 + \dots + v_n w_n =
            \sum_{i=1}^{N} v_i w_i = \beta
        \end{equation*}
        Alternatively the following form is used to get the angle $\phi$
          between two vectors
        \begin{equation*}
          \vec{v}\cdot \vec{w} \coloneqq |\vec{v}||\vec{w}|\cos(\phi)
        \end{equation*}
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=6, title=\lsttitlelight{Vectors in numpy -- Examples for presented content}]
      print(3 * v)  # numpy multiplies componentwise per default -> array([3, 6, 9])
      print(np.linalg.norm(v))  # -> LinAlg functions -> 3,74165
      print(np.dot(v, w))  # Dot product from linalg -> 32
      print(np.rad2deg(np.arccos(
          np.dot(v, w) / np.linalg.norm(v) / np.linalg.norm(w))))  # Angle -> 12,933Â°
      \end{lstlisting}
    \end{mdframed}
  \end{frame}
% </Vectors>

% <Vector Exercise>
  \begin{frame}{Vectors}
    \begin{exampleblock}{Exercise}
      We have two 4D vectors
      \begin{equation*}
        \vec{v} = \left(1, -2, 5, 0\right)^\transp
        \quad\text{and}\quad
        \vec{w} = \left(2, 2, 3, -1\right)^\transp
      \end{equation*}
      \begin{enumerate}
        \item Calculate the lengths $|\vec{v}|$, $|\vec{w}|$
        \item Calculate the sum $\vec{v} + \vec{w}$ and difference $\vec{v} - \vec{w}$
        \item Calculate the scalar product $\vec{v}\cdot \vec{w}$
        \item What is angle $\phi$ in degrees between both vectors?
        \item Find a vector $\vec{u}\neq \vec{0}$ which is orthogonal to $\vec{v}$
      \end{enumerate}
      The \texttt{numpy} package in Python has built-in support for vector
      calculations.
      Use \texttt{numpy.dot}, \texttt{numpy.linalg.norm},
      \texttt{numpy.rad2deg}, etc. to check your calculations above or code the
      functionality yourself.
      See \url{https://numpy.org/devdocs/reference/index.html} for help.
    \end{exampleblock}
  \end{frame}
% </Vector Exercise>

% <Matrices>
  % Intro, vector identification
  \begin{frame}[fragile]{Matrices}
    \begin{itemize}
      \item A $(n, m)$ matrix $\underline{M}$ is defined as a tuple of numbers
        $a_{ij}$ ($i=1,\dots,m$, $j=1,\dots,n$)
        \begin{equation*}
          \underline{M} =
          \begin{pmatrix}
            a_{11} & a_{12} & \dots & a_{1n} \\
            a_{21} & a_{22} & \dots & a_{2n} \\
            \vdots & \vdots & & \vdots \\
            a_{m1} & a_{m2} & \dots & a_{mn} \\
          \end{pmatrix}
        \end{equation*}
      \item We can identify column vectors with $(m, 1)$ matrices and row
        vectors with $(1, n)$ matrices
        \begin{equation*}
          \underline{M}_{1,n} = \left(v_1, \dots, v_n\right)
            \leftrightarrow \vec{v}^\transp \quad\text{and}\quad
          \underline{M}_{m, 1} =
            \begin{pmatrix}w_1 \\ \vdots \\ w_m \end{pmatrix}
            \leftrightarrow \vec{w}
        \end{equation*}
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=6, title=\lsttitlelight{Matrices in numpy -- Examples for presented content}]
      M = np.array([
          [1, 2],  # [row1_col1, row1_col2]
          [3, 4]   # [row2_col1, row2_col2]
        ])
      v = np.atleast_2d([1, 2, 3])  # v has shape (1, 2) -> row vector
      vT = v.T  # Transpose support, vt has shape (2, 1) -> col vector
      \end{lstlisting}
    \end{mdframed}
  \end{frame}

  % Scalar multiplication, matrix product
  \begin{frame}{Matrices}
    \begin{itemize}
      \item Multiplication with a scalar $\alpha$ is done by multiplication of
        every element with that scalar
        \begin{equation*}
          \alpha \underline{M} =
          \begin{pmatrix}
            \alpha a_{11} & \alpha a_{12} & \dots & \alpha a_{1n} \\
            \alpha a_{21} & \alpha a_{22} & \dots & \alpha a_{2n} \\
            \vdots & \vdots & & \vdots \\
            \alpha a_{m1} & \alpha a_{m2} & \dots & \alpha a_{mn} \\
          \end{pmatrix}
        \end{equation*}
      \item Matrix products $\underline{C} = \underline{A}\,\underline{B}$ are
        defined component-wise by
        \begin{equation*}
          c_{ij} = \sum_{k=1}^{n} a_{ik}b_{kj}
        \end{equation*}
        where $\underline{A}$ is a $(m, n)$, $\underline{B}$ a $(n, p)$ and
        $\underline{C}$ a $(m, p)$ matrix
        \begin{itemize}
          \item This is usually called
            \enquote{multiply row $i$ of $\underline{A}$ by
                     column $j$ of $\underline{B}$}
          % \item The inner index range must match, we can multiply any 2 matrices
          %   where the number of rows of the first on equals the number of columns
          %   in the second one
        \end{itemize}
      \begin{exampleblock}{Example: Matrix times vector}
        \begin{equation*}
          \begin{pmatrix}
            a_{11} & a_{12} \\ a_{21} & a_{22} \\ a_{31} & a_{32}
          \end{pmatrix}_{(3,2)}
            \begin{pmatrix}v_1 \\ v_2\end{pmatrix}_{(2,1)} =
          \begin{pmatrix}
            a_{11}v_1 + a_{12}v_2 \\
            a_{21}v_1 + a_{22}v_2 \\
            a_{31}v_1 + a_{32}v_2
          \end{pmatrix}_{(3,1)}
        \end{equation*}
      \end{exampleblock}
    \end{itemize}
  \end{frame}

  % Transpose, inverse
  \begin{frame}[fragile]{Matrices}
    \begin{itemize}
      \item The transpose of a matrix is obtained by switching
        elements $a_{ij}\leftrightarrow a_{ji}$
        \begin{equation*}
          \underline{M}^\transp =
          \begin{pmatrix}
            a_{11} & a_{12} & \dots & a_{1n} \\
            a_{21} & a_{22} & \dots & a_{2n} \\
            \vdots & \vdots &  & \vdots \\
            a_{m1} & a_{m2} & \dots & a_{mn} \\
          \end{pmatrix}^\transp =
          \begin{pmatrix}
            a_{11} & a_{21} & \dots & a_{m1} \\
            a_{12} & a_{22} & \dots & a_{m2} \\
            \vdots & \vdots &  & \vdots \\
            a_{1n} & a_{2n} & \dots & a_{mn} \\
          \end{pmatrix}
        \end{equation*}
      \item The inverse $\underline{M}^{-1}$ of a matrix is defined so that
        \begin{equation*}
          \underline{M}^{-1}\underline{M} =
          \underline{M}\,\underline{M}^{-1} = \underline{1}
        \end{equation*}
        where $\underline{1}$ is the identity matrix
        ($1$ on diagonal, $0$ everywhere else)
        \begin{itemize}
          \item The inverse can be found by solving a set of linear equations
            using the definition above
          \item Note: Not every matrix has an inverse!
          \item For $(2,2)$ matrices the inverse can be explicitly calculated by
            \begin{equation*}
              \begin{pmatrix} a & b \\ c & d \end{pmatrix}^{-1} =
              \frac{1}{ad-bc}
                \begin{pmatrix} d & -b \\ -c & a \end{pmatrix}
            \end{equation*}
        \end{itemize}
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=6, title=\lsttitlelight{Matrices in numpy -- Examples for presented content}]
      print(np.linalg.inv(np.array([[1, 2], [3, 4]])))  # -> [[-2.   1. ], [ 1.5 -0.5]]
      \end{lstlisting}
    \end{mdframed}
  \end{frame}
% </Matrices>

% <Matrix Exercises>
  \begin{frame}{Matrices}
    \begin{exampleblock}{Exercise}
      \begin{enumerate}
        \item We have 2 matrices $\underline{A}, \underline{B}$
          and a vector $\vec{v}$
          \begin{equation*}
            \underline{A} =
              \begin{pmatrix} 1 & 2 & 3 \\ 3 & 2 & 1 \end{pmatrix}
            \,\text{, }\quad
            \underline{B} =
              \begin{pmatrix} 0 & 2 \\ 1 & -1 \\ 0 & 1 \end{pmatrix}
            \,\text{, }\quad
            \vec{v} = \begin{pmatrix} 4 \\ 5 \\ 6 \end{pmatrix}
          \end{equation*}
          Calculate $\underline{A}\,\underline{B}$,
          $\underline{B}\,\underline{A}$,
          $\underline{A}\,\vec{v}$ and $\vec{v}^\transp\,\underline{B}$.
        \item Calculate the inverses (if existing) of
          \begin{equation*}
            \underline{A} =
              \begin{pmatrix} 1 & 2 \\ 4 & 2 \end{pmatrix}
            \quad\text{, }\quad
            \underline{B} =
              \begin{pmatrix} 1 & 2 \\ 2 & 4 \end{pmatrix}
          \end{equation*}
        \item We have a matrix $\underline{M} = \underline{1}$
          and a vector $\vec{v}^\transp = \left(v_1, v_2, v_3\right)$.
          Calculate $\vec{v}^\transp\, \underline{M}\, \vec{v}$
      \end{enumerate}
    \end{exampleblock}
  \end{frame}
% </Matrix Exercises>

% <Convolution>
  \begin{frame}{Convolution}
    \begin{itemize}
      \item Mathematically
        \begin{equation*}
          \left(f * g\right)(t) \coloneqq
            \int_{-\infty}^\infty f(\tau)g(t-\tau)\deriv{\tau}
        \end{equation*}
      \begin{itemize}
        \item Intuitive: $f$ is a \enquote{signal}, $g$ is a \enquote{response}.
          At time $t$ the convolution gives the (causal, thus we mirror $g$)
          system response for input $f$ and response $g$ by summing (integrating)
          all infinitesimal mini-responses up to $t$
          \item Imagine $f$ being decomposed in \enquote{delta} peaks and $g$
            acts independently on each input impulse
      \end{itemize}
      \item See following examples below for how each point of the convolution function is constructed.
    \end{itemize}

    \includegraphics[width=\textwidth]{01-img-convolution_analytic.png}
  \end{frame}
  \begin{frame}{Convolution}
    \includegraphics[width=\textwidth]{01-img-convolution_analytic_B.png}

    \includegraphics[width=\textwidth]{01-img-convolution_analytic_C.png}
  \end{frame}
% </Convolution>

% <Discrete convolution>
  \begin{frame}{Discrete convolution}
    \begin{columns}[t]
      \begin{column}{0.7\textwidth}
        \begin{itemize}
          \item Here we need the discrete version, replacing integrals with sums and functions with arrays of numbers ($f(x)\rightarrow f[i]$)
            \begin{equation*}
              (f*g)[i] = \sum_{k=-\infty}^{\infty} f[k]g[i-k]
            \end{equation*}
          \item In real applications the kernel or the signal has some finite support (there are no infinite length arrays), so the sum will be constrained by some range $\{-N, -N+1, \dots, N-1, N\}$.
          \item Usually the signal and kernel is supposed to start at time $t=0$ at the first index (causality), so the kernel is applied with its leftmost value first (compare 2D convolution)
          \item Finite support leads to problems at the borders of $f$
          \item Multiple strategies exist, eg. padding with zero, mirroring at the border, cyclic repetition or repeating the outermost element
        \end{itemize}
      \end{column}
      \begin{column}{0.3\textwidth}
        % \vspace{1em}
        \begin{center}
          \includegraphics[height=0.8\textheight]{01-img-convolution_discrete.png}
        \end{center}
      \end{column}
    \end{columns}
  \end{frame}

  \begin{frame}{Discrete convolution}
    \includegraphics[width=\textwidth]{01-img-convolution_discrete_B.png}
    \includegraphics[width=\textwidth]{01-img-convolution_discrete_C.png}
  \end{frame}
% </Discrete convolution>

% <Discrete convolution in 2D>
  \begin{frame}{Discrete convolution in 2D}
    \begin{itemize}
      \item In two dimensions, convolutions work the same way
        \begin{equation*}
          (f*g)[i, j] =
          \sum_{k=-\infty}^{\infty} \sum_{l=-\infty}^{\infty} f[k,l]g[i-k, j-l]
        \end{equation*}
      \item Same here with the finite support
      \item In image applications, the response is often called kernel or filter
      \item Don't forget to flip the kernel horizontally and vertically before
        computing the elementwise multiplication
      \item In image applications, the kernel is usually used centered over the original image (eg. $3\times 3$ kernel is applied with its center pixel over the pixel that is currently convolved)
      \item This is what is typically used in convolutional neural network layers (although technically the kernel doesn't have to flipped, because the weights are learned anyway)
    \end{itemize}
    \begin{exampleblock}{Example}
      \begin{equation*}
        \begin{bmatrix}
          1 & 2 & 3 \\ 4 & \ccga\tcw{5} & 6 \\ 7 & 8 & 9
        \end{bmatrix} \, *
        \begin{bmatrix}
          -1 & -2 & -1 \\ 0 & \ccga\tcw{0} & 0 \\ 1 & 2 & 1
        \end{bmatrix}  \rightarrow
        \begin{bmatrix}
          - & - & - \\ - & \ccga\tcw{-24} & - \\ - & - & -
        \end{bmatrix}\minter{, with $0$ padding:}
          \begin{bmatrix}
            -13 & -20 & -17 \\ -18 & \ccga\tcw{-24} & -18 \\ 13 & 20 & 17
          \end{bmatrix}
      \end{equation*}
    \end{exampleblock}
  \end{frame}
% </Discrete convolution in 2D>

% <Convolution Exercises>
  \begin{frame}{Convolution}
    \begin{exampleblock}{Exercise}
    For the following exercises, pad the signal function with zeroes where
    appropriate.
    % Additionally you can also try cyclic, mirrored or \enquote{repeated} edges or only calculate the convolution where the signal is valid.
      \begin{enumerate}
        \item Consider a discrete signal
          \begin{equation*}
            f[i] = \{f[i=0] = 3 \}
          \end{equation*}
          (value of $3$ at position $i=0$) and a response
          \begin{equation*}
            g[i] = \left\{g[i=0] = 2, g[i=1] = 1\right\}
          \end{equation*}
          Compute the convolution $f*g$ for all non-zero components.
        \item Now we have a more complicated signal
          \begin{equation*}
            f[i] = \left\{f[i=0] = 3, f[i=1] = 4, f[i=2] = 5\right\}
          \end{equation*}
          Compute $f*g$ with the same kernel $g$ as above. \\
          {\footnotesize Tip: \emph{For grasping the concept of why the kernel is flipped, try
          to imagine how each signal contribution triggers the response. The
          response needs some time to arrive at the current index which in the
          end gives you the flipped kernel in the formula.}}
      \end{enumerate}
    \end{exampleblock}
  \end{frame}
% </Convolution Exercises>

% <Convolution Exercises>
  \begin{frame}{Convolution}
    \begin{exampleblock}{Exercise}
      \begin{enumerate}
        \item[3] Now we try a 2D convolution.
          Convolve the following $8x8$ "grayscale image"
          \begin{equation*}
            \text{Img} = \quad \begin{matrix}
                \ccb \tcw{0.0} & \ccga 0.5 & \ccga 0.5 & \ccga 0.5 & \ccga 0.5 & \ccga 0.5 & \ccga 0.5 & \ccb \tcw{0.0} \\
                \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccga 0.5 & \ccga 0.5 & \ccga 0.5 & \ccga 0.5 & \ccb \tcw{0.0} & \ccb \tcw{0.0} \\
                \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} \\
                \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} \\
                \ccb \tcw{0.0} & 1.0 & 1.0 & \ccb \tcw{0.0} & \ccb \tcw{0.0} & 1.0 & 1.0 & \ccb \tcw{0.0} \\
                \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccb \tcw{0.0} \\
                \ccb \tcw{0.0} & \ccb \tcw{0.0} & \ccgc 0.7 & \ccgb 0.6 & \ccgb 0.6 & \ccgc 0.7 & \ccb \tcw{0.0} & \ccb \tcw{0.0} \\
                \ccga 0.5 & \ccb \tcw{0.0} & \ccgc 0.7 & \ccgc 0.7 & \ccgc 0.7 & \ccgc 0.7 & \ccb \tcw{0.0} & \ccga 0.5
            \end{matrix}
          \end{equation*}
          with a $3x3$ top to bottom Sobel kernel (gradient kernel for edge finding):
          \begin{equation*}
            \begin{pmatrix}
              1 & 2 & 1 \\
              0 & 0 & 0 \\
              -1 & -2 & -1
            \end{pmatrix}
          \end{equation*}
        Interpret the results.
      \end{enumerate}
    \end{exampleblock}
  \end{frame}
% </Convolution Exercises>

% functions %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Functions}

% <Functions>
  \begin{frame}[fragile]{Functions}
    \begin{itemize}
      \item Functions define a mapping from one set to another
      \item Typically we deal with loss functions $f:\mathbb{R}^n \rightarrow \mathbb{R}$ mapping from many to a single real number or vector functions $f:\mathbb{R}^n \rightarrow \mathbb{R}^m$ mapping from many to many real numbers
      \item Loss functions can have from a few to millions of input parameters and usually map to a single number
      \item In neural networks, the layer connections are built using vector functions
      \item Functions can be composed by applying each mapping in order, eg. for two functions $f, g$
      \begin{equation*}
        (g\circ f)(x) = g(f(x))
      \end{equation*}
      which means applying first $f$ on $x$ and then $g$ on the result of $f(x)$
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=8, title=\lsttitlelight{Composing functions in Python}]
        f = lambda x: x**2
        g = lambda x: x + 1.
        h = lambda x: x / 2.
        def comp(x):
            return h( g( f( x ) )

        print( comp(np.arange(5)) )  # -> [0.5, 1., 2.5, 5., 8.5]
      \end{lstlisting}
    \end{mdframed}
  \end{frame}
% </Functions>

% <Derivatives>
  \begin{frame}{Derivatives}
    \begin{itemize}
      \item We often need to know how fast or slow a function changes at a specific point, this is computed using the derivative
      \begin{equation*}
        \dderiv{f}{x} = \lim\limits_{h\rightarrow 0} \frac{f(x+h) - f(x)}{h}
      \end{equation*}
      \item For functions of many parameters, the partial derivative is the derivative of the function considering only a single parameter
      \begin{equation*}
        \ddel{f}{x_i} = \lim\limits_{h\rightarrow 0}
          \frac{f(x_0, \dots, x_i+h, \dots) - f(\vec{x})}{h}
      \end{equation*}
    \item For vector functions the principle is the same, but with respect to each component of the vector
    \end{itemize}
    \includegraphics[width=\textwidth]{01-img-derivatives.png}
  \end{frame}
% </Derivatives>

% <Derivatives>
  \begin{frame}[fragile]{Derivatives}
    \begin{itemize}
      \item There are rules to derive many \enquote{standard} function elements like
      \begin{equation*}
        \dderiv{x^a}{x} = ax^{a-1} ,\quad \dderiv{e^x}{x} = e^x ,\quad \dderiv{\ln x}{x} = \frac{1}{x}Â ,\quad \dderiv{\sin x}{x} = \cos{x} ,\quad \dderiv{\cos x}{x} = -\sin x
      \end{equation*}
      \item Additionally there are rules that can be used when multiple functions are combined in a special arrangement ($f' \leftrightarrow \dderiv{f}{x}$)
      \begin{align*}
        (f + g)' &= f' + g' &\minter{sum\,rule} \\
        (f \cdot g)' &= f' \cdot g + f \cdot g' &\minter{product\,rule} \\
        (g \circ f)' &= (g' \circ f) \cdot f' &\minter{chain\,rule}
      \end{align*}
    \end{itemize}
    \begin{columns}[t]
      \begin{column}{0.55\textwidth}
        \begin{itemize}
          \item The chain rule is excessively used in the back-propagation algorithm to compute the gradient of a neural network
          \item The same differentiation rules hold for many parameter and vector functions \textbf{but the order matters, because we are dealing with vectors and matrices instead of single numbers}
        \end{itemize}
      \end{column}
      \begin{column}{0.45\textwidth}
        \begin{mdframed}
          \begin{lstlisting}[style=dark, gobble=12, title=\lsttitlelight{Chaining gradients in Python}]
            f = lambda x: (x**2, 2*x)
            g = lambda x: (np.sin(x), np.cos(x))
            def chain(x):
                vf, df = f(x)
                vg, dg = g(vf)
                return vg, dg * df
          \end{lstlisting}
        \end{mdframed}
      \end{column}
    \end{columns}
  \end{frame}
% </Derivatives>

% <Vector Functions>
  \begin{frame}[fragile]{$\mathbf{R}^n$ and Vector Functions}
    \begin{itemize}
      \item For functions with more than one input parameter we already saw the partial derivative
      \item The gradient collects all possible derivatives in a new vector pointing along the direction of steepest ascent for functions $f:\mathbf{R}^n\rightarrow \mathbf{R}$
      \begin{equation*}
        \vec{\nabla}_{\vec{x}} f = \left[
          \ddel{f}{x_1}, \ddel{f}{x_2}, \dots, \ddel{f}{x_n} \right]_{(1, n)}
      \end{equation*}
      \item Equivalently the Jacobi matrix collects all gradients for a vector function $f:\mathbf{R}^n\rightarrow\mathbf{R}^m$ in a $(m, n)$ matrix
      \begin{equation*}
        \underline{J} = \vec{\nabla}_{\vec{x}} \vec{f} = \left[
          \ddel{\vec{f}}{x_1}, \ddel{\vec{f}}{x_2}, \dots, \ddel{\vec{f}}{x_n} \right] =
          \begin{pmatrix}
            \ddel{f_1}{x_1} & \dots & \ddel{f_1}{x_n} \\
            \vdots & & \vdots \\
            \ddel{f_m}{x_1} & \dots & \ddel{f_m}{x_n}
          \end{pmatrix}_{(m, n)}
      \end{equation*}
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=8, title=\lsttitlelight{Checking gradients numerically}]
        x = np.linspace(-10, 10, 200)
        y = np.sin(x) * np.cos(x)
        dy_num = np.gradient(y, x)
      \end{lstlisting}
    \end{mdframed}
  \end{frame}
% </Vector Functions>

% <Exercises>
  \begin{frame}{Exercises}
    \begin{exampleblock}{Exercise}
      \begin{enumerate}
        \item Calculate the derivative of
          \begin{itemize}
            \item the polynomial $f(x) = x^3 + 6x^2 - 3x - 5$.
            \item the logistic sigmoid $f(x) = \frac{1}{1+e^{-x}}$.
            \item the composed function
              $f(z) = \ln(1 + z), z(\vec{x}) = \vec{x}^\transp \vec{x}$
              with $\vec{x}^\transp = \left[x_0, x_1, x_2\right]$
          \end{itemize}
        \item Calculate the gradient of the quadratic function
          \begin{equation*}
            g\left( \begin{bmatrix}x_1 \\Â x_2 \end{bmatrix} \right)
            = \frac{1}{2}
              \vec{x}^\transp \underline{W}\, \vec{x} + \vec{x}^\transp \vec{b}
            = \frac{1}{2}
              \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}^\transp
              \begin{bmatrix} 2 & 1 \\ 1 & 20 \end{bmatrix}
              \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}
              + \begin{bmatrix} x_1 \\ x_2 \end{bmatrix}^\transp
                \begin{bmatrix} -5 \\ -3 \end{bmatrix}
          \end{equation*}
          Before doing the calculation, try to determine the dimension of the gradient.
      \end{enumerate}
    \end{exampleblock}
  \end{frame}
% </Exercises>

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% STATISTICS
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \section{Statistics}
% <Probabilities>
  \begin{frame}[fragile]{Probabilities}
    \begin{itemize}
      \item Continuous distribution of a random variable $X$
        \begin{equation*}
          f(x) \quad\text{with}\quad \int_\Omega f(x) \deriv{x} = 1
        \end{equation*}
        and $f(x) \geq 0$ (probability density function, \enquote{pdf})
      \item Discrete distribution of a random variable $X$
        \begin{equation*}
          P(x_i) \quad\text{with}\quad \sum_{x_i\in\chi} P(x_i) = 1
        \end{equation*}
        and $P(x_i) \geq 0$ (probability mass function, \enquote{pmf})
      \item Cumulative distribution functions define the probability contained up to a specific interval:
      \begin{equation*}
        F(x) = \int_{\chi_0}^x f(x) \deriv{x}
        \quad \text{and} \quad
        F(n) = \sum_{i=i_\text{min}}^n P(x_i)
      \end{equation*}
      for the continuous and the discrete (only when there is an explicit order) case respectively
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=8, title=\lsttitlelight{Cumulative distribution function for discrete PDF}]
        pdf = np.array([0.6, 0.3, 0.1])
        print( np.cumsum(pdf) )  # [0.6, 0.3, 0.1] Note: Is missing first 0
      \end{lstlisting}
    \end{mdframed}
  \end{frame}

  \begin{frame}{PDF and CDF Example -- Discrete and Continuous}
    \includegraphics[width=\textwidth]{01-img-distributions.png}
  \end{frame}
% </Probabilities>

% <Mean and Variance>
  \begin{frame}[fragile]{Mean and Variance}
    \begin{itemize}
      \item The mean $<x>$ of a distribution $f(x)$ is defined as
        \begin{equation*}
          \langle x\rangle = \int_\chi xf(x) \deriv{x}
          \quad\text{or}\quad
          \langle x\rangle = \sum_{x_i\in\chi} x_iP(x_i)
        \end{equation*}
      \item In general, the expectation value $E[h]$ of a function $h(x)$ considering the distribution $f(x)$ ($P(x_i)$) of $x$ is defined as
        \begin{equation*}
          E[h] = \int_\chi h(x)f(x) \deriv{x}
          \quad\text{or}\quad
          E[h] = \sum_{x_i\in\chi} h(x_i)P(x_i)
        \end{equation*}
      \item Another important summary statistic is the variance
        \begin{equation*}
          \Var[x] = \int_\chi (x-\langle x\rangle)^2 f(x) \deriv{x}
          \quad\text{or}\quad
          \Var[x] = \sum_{x_i\in\chi} (x_i - \langle x\rangle)^2 P(x_i)
        \end{equation*}
        often used to characterize the width of a distribution
        \begin{itemize}
          \item The standard deviation $\sigma_x = \sqrt{\Var[x]}$ is also often used, because it has the same dimension as the random variable itself
        \end{itemize}
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=8, title=\lsttitlelight{Cumulative distribution function for discrete PDF}]
        data = np.random.normal(1, 2, size=(1000))
        print( np.mean(data), np.cov(data), np.std(data) )
      \end{lstlisting}
    \end{mdframed}
  \end{frame}
% </Mean and Variance>

% <Covariance and Correlation>
  \begin{frame}[fragile]{Covariance and Correlation}
    \begin{itemize}
      \item In cases with more than two variables the covariance between to random variables $(x, y)$ is defined equivalently as
        \begin{align*}
          \Cov[x, y] &= \int_\chi (x-\langle x\rangle)(y-\langle y\rangle) f(x,y) \deriv{x, y}
          \quad\text{or}\quad \\
          \Cov[x, y] &= \sum_{x_i,y_i\in\chi}(x_i - \langle x\rangle)(y_i - \langle y\rangle) P(x_i, y_i)
        \end{align*}
        with the joint distributions $f$ ($P$) of $x, y$
      \item To express the linear dependence of two random variables $x, y$ the correlation is used
      \begin{equation*}
        \rho_{x,y} = \frac{\Cov[x, y]}{\Var[x]\Var[y]}
      \end{equation*}
      which is the normalized covariance in the interval $[-1, +1]$
      \begin{itemize}
        \item When $\Cov[x,y] = 0$, $x,y$ are statistically independent leading to $f(x,y) = f(x)f(y)$. The reverse is not automatically given though
      \end{itemize}
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=8, title=\lsttitlelight{Cumulative distribution function for discrete PDF}]
        x = np.random.normal(0, 1, size=1000)
        y = np.random.normal(x, x**2, size=1000)
        print( np.cov(x, y), np.corrcoef(x, y) )
      \end{lstlisting}
    \end{mdframed}
  \end{frame}
% </Covariance and Correlation>

% <Bayes Rule>
  \begin{frame}{Bayes' Rule}
    \begin{itemize}
      \item With the two prerequisites $\dots$
        \begin{enumerate}
          \item A multidimensional distribution can be marginalized by integrating (or summing) over all but one variable: $f(x) = \int_\mathcal{Y}f(x,y)\,\deriv{y}$ or $P(x) = \sum_{y_i\in\mathcal{Y}} P(x_i, y_i)$
          \item The following intuitive properties can be visualized and understood using Venn diagrams
            \begin{equation*}
              P(A\,\text{or}\,B) = P(A) + P(B) - P(A\,\text{and}\,B)
              \minter{and}
              P(A\,\text{and}\,B) = P(A) P(B|A) = P(B) P(A|B)
            \end{equation*}
        \end{enumerate}
      \item $\dots$ the Bayes' rule follows
        \begin{equation*}
          P(A|B) = \frac{P(B|A) P(A)}{P(B)}
          \minter{, or more general for disjunct $A_i$:}
          P(A_i|B) = \frac{P(B|A_i) P(A_i)}{\sum_{i=1}^N P(B|A_i)P(A_i)}
        \end{equation*}
        \begin{itemize}
          \item $P(B|A)$ is the \enquote{Likelihood} (data), $P(A)$ the \enquote{Prior} (believe), $P(B)$ the \enquote{marginalization} (normalization)
          \item $P(A|B)$ is the \enquote{Posterior}, the probability of $B$ being true, given $A$ is true (prior information)
        \end{itemize}
    \end{itemize}
    \vfill
    \begin{exampleblock}{Example: Drug test reliability}
      A drug test is $97\%$ positive if truly positive, $95\%$ negative if truly negative (Likelihood). \\
      Also known (Prior): $0.5\%$ of the population is known to use the drug. What is the probability that a random person with a positive test is really using the drug? \\
      Answer: Only $8.9\%$ chance that a positively tested person is really using the drug (Posterior).
    \end{exampleblock}
  \end{frame}
% </Bayes Rule>

% <Important Distributions>
  \begin{frame}{Important Distributions}
    \begin{itemize}
      \item Gaussian distribution in $d$ dimensions
        \begin{equation*}
          \mathcal{N}(\vec{x}|\vec{\mu},\underline{\Sigma})
          = \frac{\det{\underline{\Sigma}^{-1}}}{(2\pi)^{d/2}}
            \exp\left(
              -\frac{1}{2} (\vec{x}-\vec{\mu})^\transp
              \underline{\Sigma}^{-1} (\vec{x}-\vec{\mu})
            \right)
        \end{equation*}
        with mean $\vec{\mu}$ and covariance matrix $\underline{\Sigma}$
      \item Binomial distribution
        \begin{equation*}
          P(k|n,p) = \begin{pmatrix} n \\ k \end{pmatrix} p^k (1-p)^{n-k}
          \quad\text{for}\, k = 0, 1, \dots, n
        \end{equation*}
        describing the probability of getting $k$ successes in $n$ trials with a chance $p$ of getting a success in each trial
      \item Poisson distribution
      \begin{equation*}
        P(k|\lambda) = \frac{\lambda^k}{k!}\,e^{-\lambda}
      \end{equation*}
      describing the chance of counting $k$ hits within a defined time interval under a given expectation $\lambda$.\\
      It is a special case of the binomial distribution for small $p$ and many trials $n$
    \end{itemize}
  \end{frame}

  \begin{frame}{Distributions -- Examples}
    \includegraphics[width=\textwidth]{01-img-distributions_examples.png}
  \end{frame}
% </Important Distributions>

% <Exercises>
  \begin{frame}{Exercises}
    \begin{exampleblock}{Exercise}
      \begin{enumerate}
        \item Compute the mariginal distributions $p(x), p(y)$ and the conditional distributions $p(x|Y=y_1), p(y|X=x_3)$ for the bivariate discrete distribution
        \begin{center}
          \begin{tabular}{r|ccccc}
             & $x_1$ & $x_2$ & $x_3$ & $x_4$ & $x_5$ \\ \hline
            $y_1$ & $0.01$ & $0.02$ & $0.03$ & $0.1$ & $0.1$ \\
            $y_2$ & $0.05$ & $0.1$ & $0.05$ & $0.07$ & $0.2$ \\
            $y_3$ & $0.1$ & $0.05$ & $0.03$ & $0.05$ & $0.04$ \\
          \end{tabular}
        \end{center}
        \item You have collected the following data about spam emails:
        \begin{center}
          \begin{tabular}{ll|ll}
            Type & Contains & Type & Contains \\ \hline
            spam & \enquote{send us your password} &
              spam & \enquote{review us} \\
            no-spam & \enquote{send us your review} &
              spam & \enquote{send password} \\
            no-spam & \enquote{password review} &
              spam & \enquote{send us your account} \\
          \end{tabular}
        \end{center}
          What is the posterior probability that a new email containing the word \enquote{review} is a spam mail?
          You may also write a little code to make the example bigger or play with the parameters.
        \item Now try to compute the probability of \enquote{review us now} by constructing likelihoods for every occurring word.
        % http://www.est.uc3m.es/BayesUC3M/Summer_School_UPM/2017/lecture%20notes/Practical1.pdf page 5ff.
      \end{enumerate}
    \end{exampleblock}
  \end{frame}
% </Exercises>

% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% MINIMIZERS
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
  \section{Minimization and Gradient Descent}
% <Analytical>
  \begin{frame}{Overview}
    \begin{itemize}
      \item Analytically we can find all stationary points of a (reasonably normal) function by finding the point where the first derivative is zero (or gradient for multidimensional functions)
      \begin{equation*}
        \dderiv{f}{x} = 0 \quad\text{or}\quad\nabla_{\vec{x}}f = \vec{0}
      \end{equation*}
      \item Any minima also needs to have a second derivative smaller than zero (or a positive definite Hessian)
      \item However, numerically finding the global minimum is extremely hard in general but multiple strategies exist for finding a local one (bisection, Newton methods, gradient descent, ...)
      \item Here we focus on the gradient descent method as it is widely used due to it's simplicity and its reliance on the gradient only
      \begin{itemize}
        \item Another popular method, especially used for root finding is the Newton method.
        However due to its costly need for inverse second derivatives, it is seldom used in high dimensional optimization problems
        \item Some approximative methods exist, that try to approximate the inverse second derivatives with a reasonable amount of computation
        \item Read \url{docs.scipy.org/doc/scipy/reference/tutorial/optimize.html} for a nice overview
      \end{itemize}
    \end{itemize}
  \end{frame}
% </Analytical>

% <Gradient Descent>
  \begin{frame}[fragile]{Gradient Descent}
    \begin{itemize}
      \item Function decreases the fastest in the direction of the negative gradient
      \item Define iterative method
        \begin{equation*}
          \vec{\theta}_{i+1}
          = \vec{\theta}_i - \gamma_i (\nabla_{\vec{\theta}}f)(\vec{\theta}_i)
        \end{equation*}
        with a \enquote{suitably small} step size $\gamma_i$ (often also called \enquote{learning rate})
      \item The chose of the step size is crucial. Too small and the convergence is very slow, too large and convergence cannot be guaranteed
      \item Selecting the proper step size $\gamma_i$ is often done using a \enquote{line search} algorithm, which tries to find a minimum along the gradient direction, making it a 1D sub-problem
      \begin{equation*}
        \gamma_i = \argmin_\gamma F(\gamma) \minter{with}
        F(\gamma) = f(x + \gamma (\nabla_{\vec{\theta}}f)(\vec{\theta}_i))
      \end{equation*}
      \begin{itemize}
        \item A simple approach is backtracking: If $f(\vec{\theta}_{i+1}) \geq f(\vec{\theta}_i)$, decrease learning rate and try again
      \end{itemize}
      \item Often a fixed learning rate decay schedule (eg. exponential) is preferred, to step more carefully when further advanced or some heuristics are used to adapt the learning rate
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=6, title=\lsttitlelight{Example Implementation}]
        for i in range(nepochs):
            grad = get_gradient(func, params, data)
            params = params - learning_rate * grad
      \end{lstlisting}
    \end{mdframed}
  \end{frame}

  \begin{frame}{Gradient Descent - Example with different learning rates}
    \begin{itemize}
      \item Using a constant learning rate is very problem dependent and usually not recommended as it needs a lot of fine tuning.
    \end{itemize}
    \includegraphics[width=\textwidth]{01-img-gradient_descent.png}
  \end{frame}
  \begin{frame}{Gradient Descent - Example of very simple backtracking adaptive step size}
    \begin{itemize}
      \item Adaptive learning rate with very simple backtracking approach.
    Learning rate can only decrease and is reset to original value in each descent step.
    \end{itemize}
    \includegraphics[width=\textwidth]{01-img-gradient_descent_B.png}
  \end{frame}
% </Gradient Descent>

% <Stochastic Gradient Descent>
  \begin{frame}[fragile]{Stochastic Gradient Descent}
    \begin{itemize}
      \item For loss functions, the function value and thus the gradient usually depend on a sum of functions over all considered data samples $\{x\}, \{y\}$: $L(\theta, \{x\}, \{y\}) = \sum_n f(\theta |Â x_n, y_n)$
      \item For a gradient descent step the sum over all gradients must be calculated, which can be very costly for high dimensional data and / or a large training sample $\theta_{i+1} = \theta_i - \gamma_i \sum_n \nabla f(\theta_i |Â x_n, y_n)$
      \item Stochastic gradient descent therefore only uses a single data point to update the gradient in each iteration to update the parameters
      \begin{equation*}
        \theta_{i+1} = \theta_i - \gamma_i f(\theta_i |Â x_n, y_n)
      \end{equation*}
      \begin{itemize}
        \item This enables to train on every new example (\enquote{online}) and speeds the process up
        \item But also introduces more variance in the descent step
      \end{itemize}
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=6, title=\lsttitlelight{Example Implementation}]
        for i in range(nepochs):
            data = random_shuffle(data)
            for single_data_point in data:
              grad = get_gradient(func, params, single_data_point)
              params = params - learning_rate * grad
      \end{lstlisting}
    \end{mdframed}
  \end{frame}

  \begin{frame}[fragile]{Stochastic Gradient Descent}
    \begin{itemize}
      \item \enquote{Mini-batch} gradient descent is a hybrid solution uses a a subset $1 < N_B < N$ of randomly sampled data point in each update step
      \begin{equation*}
        \theta_{i+1}
        = \theta_i - \gamma_i \sum_n^{N_s} \nabla f(\theta_i |Â x_n, y_n)
      \end{equation*}
      \begin{description}
        \item[\enquote{batch-size}] is the number of data points $N_B$ used per gradient update step
        \item[An \enquote{epoch}:] is over when the whole training set was exactly used once to update the parameters
        \item[A \enquote{step}] is the single gradient update step, from which there are $N / N_S$
      \end{description}
      \item If training for more than one epoch, the data is usually shuffled in each one to prevent using the exact same batches in the exact same order every time
    \end{itemize}
    \begin{mdframed}
      \begin{lstlisting}[style=dark, gobble=6, title=\lsttitlelight{Example Implementation}]
        for i in range(nepochs):
            data = random_shuffle(data)
            for batch_data in get_batch(data, size=batch_size):
              grad = get_gradient(func, params, batch_data)
              params = params - learning_rate * grad
      \end{lstlisting}
    \end{mdframed}
  \end{frame}
% </Stochastic Gradient Descent>

% <Momentum Gradient Descent>
  \begin{frame}{Momentum Gradient Descent}
    \begin{itemize}
      \item For the usually high dimensional and non-convex loss function encountered in deep learning applications, standard gradient descent tends to get stuck in local minima, overshoot the global one or converge very slow in steep and long \enquote{valleys} of the loss function.
      \item To counter these issues, momentum gradient descent can be used
      \item Momentum gradient descent uses a linear combination of the current and last gradient, which acts like persisting momentum in a physical sense and enables the gradient descent step to move over small local minima
      \begin{align*}
        \vec{\theta}_{i+1} &= \vec{\theta}_i
          - \gamma_i (\nabla_{\vec{\theta}}f)(\vec{\theta}_i)
          + \alpha\Delta \vec{\theta}_i \\
        \text{where}\quad \Delta x_i &= \vec{\theta}_i - \vec{\theta}_{i-1}
          = \alpha \Delta \vec{\theta}_{i-1}
            - \gamma_{i-1} (\nabla_{\vec{\theta}}f)(\vec{\theta}_{i-1})
      \end{align*}
      with $\alpha\in[0, 1]$
      \item For stochastic gradient descent, using momentum decreases the variance the weighted averaging over two gradient steps.
      \begin{itemize}
        \item Typically $\alpha$ is set between $0.5$ and $0.9$ but needs to be tuned per problem.
      \end{itemize}
      \item A nice overview of modern gradient descent approaches can be found here:
      \begin{itemize}
        \item \url{https://ruder.io/optimizing-gradient-descent} for a very good more in-depth intro
        \item \url{keras.io/optimizers} for implementations of these algorithms
      \end{itemize}
    \end{itemize}
  \end{frame}

  \begin{frame}{Momentum Gradient Descent - Example using momentum in valleys}
    \begin{itemize}
      \item Using momentum can help to converge faster (or at all) in valley-like environments.
    \end{itemize}
    \includegraphics[width=\textwidth]{01-img-gradient_descent_momentum.png}
  \end{frame}
% </Momentum Gradient Descent>

% <Exercises>
  \begin{frame}{Exercises}
    \begin{exampleblock}{Exercise}
      \begin{enumerate}
        \item Why is an exact or sophisticated line search approach not used in stochastic gradient descent methods?
        \item Find the stationary points of the univariate function $f(x) = x^3 + 6x^2 - 3x - 5$ and indicate whether they are maxima, minima or saddle points.
        \item For the function $g$ in the exercises of the \emph{Functions} chapter, use the gradient descent algorithm to find the minimum and track the taken steps. Start from $\vec{x}_0 = \left[-3, -1\right]^\transp$, break if the function value does not change more than $10^{-3}$.
        Play around with different learning rates (Tip: $\gamma = 0.085$ works well).
        \item Use the weight matrix $[[2, 1], [1, 200]]$ for $g$ instead and see how standard gradient descent has problems. Use momentum or adaptive learning rate to counteract them and compare.
      \end{enumerate}
    \end{exampleblock}
  \end{frame}
% </Exercises>

\end{document}
